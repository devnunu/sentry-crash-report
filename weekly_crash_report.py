"""
Sentry ì£¼ê°„ Android í¬ë˜ì‹œ ë¦¬í¬íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ë§¤ì£¼ ì›”ìš”ì¼ì— ì§€ë‚œ 7ì¼ê°„ì˜ í¬ë˜ì‹œ í˜„í™©ì„ ë¶„ì„í•˜ì—¬ Slackìœ¼ë¡œ ì „ì†¡
"""

import json
import os
import re
import time
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import Dict, Tuple, List

import requests

# dotenv ì§€ì› (ë¡œì»¬ í™˜ê²½)
try:
    from dotenv import load_dotenv
    env_path = Path('.env')
    if env_path.exists():
        load_dotenv()
        print("âœ… .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
except ImportError:
    pass

# í™˜ê²½ ë³€ìˆ˜ í™•ì¸
SENTRY_TOKEN = os.getenv('SENTRY_AUTH_TOKEN')
ORG_SLUG = os.getenv('SENTRY_ORG_SLUG')
PROJECT_SLUG = os.getenv('SENTRY_PROJECT_SLUG')
PROJECT_ID = os.getenv('SENTRY_PROJECT_ID')
SLACK_WEBHOOK = os.getenv('SLACK_WEBHOOK_URL')
DASH_BOARD_ID = os.getenv('DASH_BOARD_ID')
ENVIRONMENT = os.getenv('SENTRY_ENVIRONMENT', 'Production')

# í…ŒìŠ¤íŠ¸ ëª¨ë“œ í™•ì¸
TEST_MODE = os.getenv('TEST_MODE', 'false').lower() == 'true'

# í…ŒìŠ¤íŠ¸ ëª¨ë“œì¼ ë•Œ ë””ë²„ê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
if TEST_MODE:
    DEBUG_DIR = Path('debug_output')
    DEBUG_DIR.mkdir(exist_ok=True)
    print("ğŸ§ª ì£¼ê°„ ë¦¬í¬íŠ¸ í…ŒìŠ¤íŠ¸ ëª¨ë“œ í™œì„±í™”")

# í™˜ê²½ ë³€ìˆ˜ ê²€ì¦
if not all([SENTRY_TOKEN, ORG_SLUG, PROJECT_SLUG, PROJECT_ID]):
    print("âŒ í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    raise ValueError("Sentry ê´€ë ¨ í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")

try:
    PROJECT_ID = int(PROJECT_ID)
except (ValueError, TypeError):
    raise ValueError("SENTRY_PROJECT_IDëŠ” ìˆ«ìì—¬ì•¼ í•©ë‹ˆë‹¤.")

# Sentry API ì„¤ì •
SENTRY_API_BASE = "https://sentry.io/api/0"
HEADERS = {
    'Authorization': f'Bearer {SENTRY_TOKEN}',
    'Content-Type': 'application/json'
}

# í•œêµ­ ì‹œê°„ëŒ€ ì„¤ì •
KST = timezone(timedelta(hours=9))


def get_weekly_datetime_range():
    """ì§€ë‚œ 7ì¼ê°„ ì‹œê°„ ë²”ìœ„ ê³„ì‚° (KST ê¸°ì¤€)"""
    target_date_str = os.getenv('TARGET_WEEK_START')

    if target_date_str:
        try:
            week_start = datetime.strptime(target_date_str, '%Y-%m-%d')
            week_start = week_start.replace(tzinfo=KST)
            print(f"ğŸ¯ ì§€ì •ëœ ì£¼ê°„ ì‹œì‘ì¼ ì‚¬ìš©: {target_date_str}")
        except ValueError:
            print(f"âš ï¸ ì˜ëª»ëœ ë‚ ì§œ í˜•ì‹: {target_date_str}. ì§€ë‚œ 7ì¼ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            now = datetime.now(KST)
            week_start = now - timedelta(days=7)
    else:
        now = datetime.now(KST)
        week_start = now - timedelta(days=7)
        print(f"ğŸ“… ê¸°ë³¸ ì£¼ê°„ ë²”ìœ„ ì‚¬ìš© (ì§€ë‚œ 7ì¼)")

    # ì´ë²ˆ ì£¼: 7ì¼ ì „ 00:00 ~ ì–´ì œ 23:59
    this_week_start = week_start.replace(hour=0, minute=0, second=0, microsecond=0)
    this_week_end = (week_start + timedelta(days=6)).replace(hour=23, minute=59, second=59, microsecond=999999)

    # ì „ì£¼: 14ì¼ ì „ 00:00 ~ 8ì¼ ì „ 23:59
    prev_week_start = this_week_start - timedelta(days=7)
    prev_week_end = this_week_start - timedelta(microseconds=1)

    # UTCë¡œ ë³€í™˜
    this_week_start_utc = this_week_start.astimezone(timezone.utc)
    this_week_end_utc = this_week_end.astimezone(timezone.utc)
    prev_week_start_utc = prev_week_start.astimezone(timezone.utc)
    prev_week_end_utc = prev_week_end.astimezone(timezone.utc)

    return {
        'this_week': (this_week_start_utc, this_week_end_utc, this_week_start),
        'prev_week': (prev_week_start_utc, prev_week_end_utc, prev_week_start)
    }


def collect_weekly_issues(start_time: datetime, end_time: datetime, week_label: str) -> List[Dict]:
    """ì£¼ê°„ ì´ìŠˆ ìˆ˜ì§‘"""
    issues_url = f"{SENTRY_API_BASE}/projects/{ORG_SLUG}/{PROJECT_SLUG}/issues/"
    all_issues = []

    start_str = start_time.isoformat()
    end_str = end_time.isoformat()

    # firstSeen ê¸°ì¤€ ì´ìŠˆ ìˆ˜ì§‘
    cursor = None
    page = 1

    while True:
        issues_params = {
            'query': f'firstSeen:>={start_str} firstSeen:<{end_str} environment:{ENVIRONMENT}',
            'limit': 100,
            'sort': 'date',
            'environment': ENVIRONMENT
        }

        if cursor:
            issues_params['cursor'] = cursor

        if TEST_MODE:
            print(f"ğŸ” {week_label} firstSeen í˜ì´ì§€ {page} ì¡°íšŒ...")

        try:
            response = requests.get(issues_url, headers=HEADERS, params=issues_params)
            if response.status_code != 200:
                break

            page_issues = response.json()
            if not page_issues:
                break

            all_issues.extend(page_issues)

            if TEST_MODE:
                print(f"   í˜ì´ì§€ {page}: {len(page_issues)}ê°œ ìˆ˜ì§‘ (ì´ {len(all_issues)}ê°œ)")

            # ë‹¤ìŒ í˜ì´ì§€ ì²´í¬
            link_header = response.headers.get('Link', '')
            if 'rel="next"' not in link_header:
                break

            cursor_match = re.search(r'cursor=([^&>]+).*rel="next"', link_header)
            if cursor_match:
                cursor = cursor_match.group(1)
                page += 1
            else:
                break

        except Exception as e:
            if TEST_MODE:
                print(f"   âŒ ì˜¤ë¥˜: {str(e)}")
            break

    # lastSeen ê¸°ì¤€ ì´ìŠˆ ì¶”ê°€ ìˆ˜ì§‘
    existing_issues_params = {
        'query': f'lastSeen:>={start_str} lastSeen:<{end_str} environment:{ENVIRONMENT}',
        'limit': 100,
        'sort': 'date',
        'environment': ENVIRONMENT
    }

    existing_cursor = None
    existing_page = 1

    while True:
        if existing_cursor:
            existing_issues_params['cursor'] = existing_cursor

        try:
            response = requests.get(issues_url, headers=HEADERS, params=existing_issues_params)
            if response.status_code != 200:
                break

            existing_issues = response.json()
            if not existing_issues:
                break

            # ì¤‘ë³µ ì œê±°í•˜ë©´ì„œ ì¶”ê°€
            existing_issue_ids = {issue.get('id') for issue in all_issues}
            new_count = 0
            for issue in existing_issues:
                if issue.get('id') not in existing_issue_ids:
                    all_issues.append(issue)
                    new_count += 1

            if TEST_MODE and existing_page <= 2:
                print(f"   {week_label} lastSeen í˜ì´ì§€ {existing_page}: {new_count}ê°œ ìƒˆë¡œ ì¶”ê°€")

            # ë‹¤ìŒ í˜ì´ì§€ ì²´í¬
            link_header = response.headers.get('Link', '')
            if 'rel="next"' not in link_header:
                break

            cursor_match = re.search(r'cursor=([^&>]+).*rel="next"', link_header)
            if cursor_match:
                existing_cursor = cursor_match.group(1)
                existing_page += 1
            else:
                break

        except Exception as e:
            if TEST_MODE:
                print(f"   âŒ {week_label} lastSeen ì˜¤ë¥˜: {str(e)}")
            break

    return all_issues


def get_issue_events_count_accurate(issue_id: str, start_time: datetime, end_time: datetime) -> int:
    """ì •í™•í•œ ì´ìŠˆ ì´ë²¤íŠ¸ ìˆ˜ ì¡°íšŒ (ê¸°ê°„ ë‚´ ì‹¤ì œ ì´ë²¤íŠ¸ ìˆ˜)"""
    events_url = f"{SENTRY_API_BASE}/issues/{issue_id}/events/"
    total_events = 0
    cursor = None
    max_pages = 5  # ìµœëŒ€ 5í˜ì´ì§€ë¡œ ì¤„ì„ (500ê°œ ì´ë²¤íŠ¸)

    for page in range(max_pages):
        params = {
            'limit': 100
        }

        if cursor:
            params['cursor'] = cursor

        try:
            response = requests.get(events_url, headers=HEADERS, params=params, timeout=10)

            if response.status_code != 200:
                if TEST_MODE:
                    print(f"        âš ï¸ API ì‘ë‹µ ì˜¤ë¥˜: {response.status_code}")
                break

            events = response.json()
            if not events:
                break

            # ì‹œê°„ ë²”ìœ„ ë‚´ ì´ë²¤íŠ¸ë§Œ ì¹´ìš´íŠ¸
            events_in_range = 0
            for event in events:
                event_time_str = event.get('dateCreated')
                if event_time_str:
                    try:
                        event_time = datetime.fromisoformat(event_time_str.replace('Z', '+00:00'))
                        if start_time <= event_time <= end_time:
                            events_in_range += 1
                        elif event_time < start_time:
                            # ì‹œê°„ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ë©´ ì¤‘ë‹¨
                            return total_events
                    except:
                        pass

            total_events += events_in_range

            # í•´ë‹¹ ë²”ìœ„ì— ì´ë²¤íŠ¸ê°€ ì—†ìœ¼ë©´ ì¡°ê¸° ì¤‘ë‹¨
            if events_in_range == 0 and page > 0:
                break

            # ì§„í–‰ ìƒí™© í‘œì‹œ (í˜ì´ì§€ë³„)
            if TEST_MODE and events_in_range > 0:
                print(f"        ğŸ“„ í˜ì´ì§€ {page+1}: {events_in_range}ê±´ ë°œê²¬ (ëˆ„ì : {total_events}ê±´)")

            # ë‹¤ìŒ í˜ì´ì§€ ì²´í¬
            link_header = response.headers.get('Link', '')
            if 'rel="next"' not in link_header:
                break

            cursor_match = re.search(r'cursor=([^&>]+).*rel="next"', link_header)
            if cursor_match:
                cursor = cursor_match.group(1)
            else:
                break

        except requests.exceptions.Timeout:
            if TEST_MODE:
                print(f"        â° {issue_id} ì´ë²¤íŠ¸ ì¡°íšŒ íƒ€ì„ì•„ì›ƒ (í˜ì´ì§€ {page+1})")
            break
        except Exception as e:
            if TEST_MODE:
                print(f"        âš ï¸ {issue_id} ì´ë²¤íŠ¸ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            break

    return total_events


def calculate_weekly_crash_stats(all_issues: List[Dict], start_time: datetime, end_time: datetime, week_label: str) -> Dict:
    """ì£¼ê°„ í¬ë˜ì‹œ í†µê³„ ê³„ì‚° (ì •í™•í•œ ì´ë²¤íŠ¸ ìˆ˜ ì‚¬ìš©)"""
    # í¬ë˜ì‹œ ì´ìŠˆë§Œ í•„í„°ë§
    crash_issues = []
    for issue in all_issues:
        level = issue.get('level', '').lower()
        if level in ['error', 'fatal']:
            crash_issues.append(issue)

    if TEST_MODE:
        print(f"ğŸ“Š {week_label}: ì´ {len(all_issues)}ê°œ ì´ìŠˆ ì¤‘ {len(crash_issues)}ê°œ í¬ë˜ì‹œ ì´ìŠˆ")

    # ì„±ëŠ¥ ìµœì í™”: ìƒìœ„ 50ê°œë§Œ ì •í™•íˆ ì²˜ë¦¬ (API í˜¸ì¶œ ì œí•œ)
    if len(crash_issues) > 50:
        print(f"âš¡ {week_label}: í¬ë˜ì‹œ ì´ìŠˆê°€ {len(crash_issues)}ê°œë¡œ ë§ì•„ì„œ ìƒìœ„ 50ê°œë§Œ ì •í™•íˆ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
        crash_issues_sorted = sorted(crash_issues, key=lambda x: safe_int(x.get('count', 0)), reverse=True)
        crash_issues = crash_issues_sorted[:50]

    total_events = 0
    all_affected_users = set()
    processed_issues = []

    for i, issue in enumerate(crash_issues):
        issue_id = issue.get('id')
        if not issue_id:
            continue

        # ì§„í–‰ ìƒí™© í‘œì‹œ
        if (i + 1) % 5 == 0 or i == 0:
            print(f"   ğŸ”„ {week_label}: {i + 1}/{len(crash_issues)} í¬ë˜ì‹œ ì´ìŠˆ ì²˜ë¦¬ ì¤‘...")

        # ì •í™•í•œ ì´ë²¤íŠ¸ ìˆ˜ ì¡°íšŒ
        event_count = get_issue_events_count_accurate(issue_id, start_time, end_time)

        if event_count > 0:
            issue['weekly_event_count'] = event_count
            total_events += event_count

            # ì‚¬ìš©ì ìˆ˜ ì¶”ì • (ë” ë³´ìˆ˜ì ìœ¼ë¡œ)
            estimated_users = min(event_count, safe_int(issue.get('userCount', 0)))
            issue['weekly_users'] = estimated_users

            # ì „ì²´ ì‚¬ìš©ìì— ì¶”ê°€
            for user_idx in range(estimated_users):
                all_affected_users.add(f"{issue_id}_{user_idx}")

            processed_issues.append(issue)

            if TEST_MODE and i < 3:
                print(f"      âœ… {issue.get('title', '')[:30]}... : {event_count}ê±´")

        # API í˜¸ì¶œ ê°„ ë”œë ˆì´ (rate limit ë°©ì§€)
        if (i + 1) % 5 == 0:
            time.sleep(0.2)

    total_affected_users = len(all_affected_users)

    print(f"   âœ… {week_label} ì™„ë£Œ:")
    print(f"      - í¬ë˜ì‹œ ì´ë²¤íŠ¸: {total_events}ê±´")
    print(f"      - í¬ë˜ì‹œ ì´ìŠˆ: {len(processed_issues)}ê°œ")
    print(f"      - ì˜í–¥ ì‚¬ìš©ì: {total_affected_users}ëª…")

    return {
        'total_crashes': total_events,
        'total_issues': len(processed_issues),
        'affected_users': total_affected_users,
        'issues': processed_issues
    }


def collect_daily_crash_data_simple(week_start_utc: datetime) -> List[int]:
    """ì¼ê°„ ë¦¬í¬íŠ¸ ë¡œì§ì„ ì‚¬ìš©í•œ ì •í™•í•œ ì¼ë³„ í¬ë˜ì‹œ ë°ì´í„° ìˆ˜ì§‘"""
    daily_crashes = []
    days = ['ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† ', 'ì¼']

    print(f"   ğŸ“Š 7ì¼ê°„ ì¼ë³„ í¬ë˜ì‹œ ë¶„ì„ ì‹œì‘...")

    # ê¸°ì¤€ ì‹œê°„ì„ KSTë¡œ ë³€í™˜
    week_start_kst = week_start_utc.astimezone(KST)
    print(f"   ğŸ• ê¸°ì¤€ ì‹œì‘ ì‹œê°„ (KST): {week_start_kst.strftime('%Y-%m-%d %H:%M:%S')}")

    # 7ì¼ê°„ ê°ê° ì¼ê°„ ë¦¬í¬íŠ¸ ë¡œì§ ì ìš©
    for day in range(7):
        # KST ê¸°ì¤€ìœ¼ë¡œ ë‚ ì§œ ë²”ìœ„ ê³„ì‚°
        day_kst_start = week_start_kst + timedelta(days=day)
        day_kst_start = day_kst_start.replace(hour=0, minute=0, second=0, microsecond=0)  # 00:00:00
        day_kst_end = day_kst_start.replace(hour=23, minute=59, second=59, microsecond=999999)  # 23:59:59

        # KSTë¥¼ UTCë¡œ ë³€í™˜
        day_start_utc = day_kst_start.astimezone(timezone.utc)
        day_end_utc = day_kst_end.astimezone(timezone.utc)

        day_name = days[day]

        # ìƒì„¸í•œ ì‹œê°„ ë²”ìœ„ ì¶œë ¥
        print(f"   ğŸ”„ [{day+1}/7] {day_name}ìš”ì¼ ë¶„ì„:")
        print(f"      ğŸ“… KST: {day_kst_start.strftime('%Y-%m-%d %H:%M:%S')} ~ {day_kst_end.strftime('%Y-%m-%d %H:%M:%S')}")

        # ì¼ê°„ ë¦¬í¬íŠ¸ì™€ ë™ì¼í•œ ë¡œì§ìœ¼ë¡œ í•´ë‹¹ ë‚ ì§œ ì´ìŠˆ ìˆ˜ì§‘ (UTC ì‹œê°„ ì‚¬ìš©)
        day_issues = collect_issues_for_date(day_start_utc, day_end_utc)

        # í¬ë˜ì‹œ ì´ë²¤íŠ¸ ìˆ˜ ê³„ì‚° (ì¼ê°„ ë¦¬í¬íŠ¸ ë¡œì§)
        day_crashes = calculate_crash_stats_for_date(day_issues, day_start_utc, day_end_utc)

        daily_crashes.append(day_crashes)

        print(f"      âœ… {day_name}ìš”ì¼ ({day_kst_start.strftime('%m/%d')}): {day_crashes}ê±´")
        print()  # ë¹ˆ ì¤„ ì¶”ê°€ë¡œ ê°€ë…ì„± í–¥ìƒ

        # API í˜¸ì¶œ ê°„ ë”œë ˆì´
        time.sleep(0.3)

    print(f"   ğŸ“ˆ ì¼ë³„ ë¶„ì„ ì™„ë£Œ: {daily_crashes}")
    print(f"   ğŸ“ˆ ì´í•© ê²€ì¦: {sum(daily_crashes)}ê±´")
    return daily_crashes


def collect_issues_for_date(start_time: datetime, end_time: datetime) -> List[Dict]:
    """íŠ¹ì • ë‚ ì§œì˜ ëª¨ë“  ì´ìŠˆ ìˆ˜ì§‘ (ì›ë˜ ë°©ì‹ìœ¼ë¡œ ë³µì›)"""

    start_str = start_time.isoformat()
    end_str = end_time.isoformat()

    issues_url = f"{SENTRY_API_BASE}/projects/{ORG_SLUG}/{PROJECT_SLUG}/issues/"
    all_issues = []

    # firstSeen ê¸°ì¤€ ì´ìŠˆ ìˆ˜ì§‘
    cursor = None
    page = 1

    while True:
        issues_params = {
            'query': f'firstSeen:>={start_str} firstSeen:<{end_str} environment:{ENVIRONMENT}',
            'limit': 100,
            'sort': 'date',
            'environment': ENVIRONMENT
        }

        if cursor:
            issues_params['cursor'] = cursor

        try:
            response = requests.get(issues_url, headers=HEADERS, params=issues_params)

            if response.status_code != 200:
                break

            page_issues = response.json()

            if not page_issues:
                break

            all_issues.extend(page_issues)

            # ë‹¤ìŒ í˜ì´ì§€ ì²´í¬
            link_header = response.headers.get('Link', '')
            if 'rel="next"' not in link_header:
                break

            cursor_match = re.search(r'cursor=([^&>]+).*rel="next"', link_header)
            if cursor_match:
                cursor = cursor_match.group(1)
                page += 1
            else:
                break

        except Exception as e:
            break

    # lastSeen ê¸°ì¤€ ì´ìŠˆ ì¶”ê°€ ìˆ˜ì§‘
    existing_issues_params = {
        'query': f'lastSeen:>={start_str} lastSeen:<{end_str} environment:{ENVIRONMENT}',
        'limit': 100,
        'sort': 'date',
        'environment': ENVIRONMENT
    }

    existing_cursor = None
    existing_page = 1

    while True:
        if existing_cursor:
            existing_issues_params['cursor'] = existing_cursor

        try:
            response = requests.get(issues_url, headers=HEADERS, params=existing_issues_params)

            if response.status_code != 200:
                break

            existing_issues = response.json()

            if not existing_issues:
                break

            # ì¤‘ë³µ ì œê±°í•˜ë©´ì„œ ì¶”ê°€
            existing_issue_ids = {issue.get('id') for issue in all_issues}
            new_count = 0
            for issue in existing_issues:
                if issue.get('id') not in existing_issue_ids:
                    all_issues.append(issue)
                    new_count += 1

            if TEST_MODE and existing_page <= 2:
                print(f"      lastSeen í˜ì´ì§€ {existing_page}: {new_count}ê°œ ìƒˆë¡œ ì¶”ê°€")

            # ë‹¤ìŒ í˜ì´ì§€ ì²´í¬
            link_header = response.headers.get('Link', '')
            if 'rel="next"' not in link_header:
                break

            cursor_match = re.search(r'cursor=([^&>]+).*rel="next"', link_header)
            if cursor_match:
                existing_cursor = cursor_match.group(1)
                existing_page += 1
            else:
                break

        except Exception as e:
            if TEST_MODE:
                print(f"      âŒ lastSeen ì˜¤ë¥˜: {str(e)}")
            break

    return all_issues


def calculate_crash_stats_for_date(all_issues: List[Dict], start_time: datetime, end_time: datetime) -> int:
    """íŠ¹ì • ë‚ ì§œì˜ í¬ë˜ì‹œ í†µê³„ ê³„ì‚° (í¬ë˜ì‹œ ì´ìŠˆë§Œ í•„í„°ë§)"""

    # í¬ë˜ì‹œ ì´ìŠˆë§Œ í•„í„°ë§ (error, fatalë§Œ)
    crash_issues = []
    for issue in all_issues:
        level = issue.get('level', '').lower()
        if level in ['error', 'fatal']:
            crash_issues.append(issue)

    if TEST_MODE:
        day_str = start_time.astimezone(KST).strftime('%m/%d')
        print(f"         ğŸ“Š {day_str}: ì´ {len(all_issues)}ê°œ ì´ìŠˆ ì¤‘ {len(crash_issues)}ê°œ í¬ë˜ì‹œ ì´ìŠˆ")

    # ì„±ëŠ¥ ìµœì í™”: ì´ìŠˆê°€ ë§ìœ¼ë©´ ì œí•œ
    if len(crash_issues) > 100:
        crash_issues_sorted = sorted(crash_issues, key=lambda x: safe_int(x.get('count', 0)), reverse=True)
        crash_issues = crash_issues_sorted[:100]

    # í¬ë˜ì‹œ ì´ë²¤íŠ¸ ìˆ˜ ê³„ì‚°
    total_events = 0
    crash_issues_with_events = []

    for i, issue in enumerate(crash_issues):
        issue_id = issue.get('id')
        if not issue_id:
            continue

        # ì§„í–‰ ìƒí™© í‘œì‹œ
        if (i + 1) % 5 == 0 or i == 0:
            day_str = start_time.astimezone(KST).strftime('%m/%d')
            print(f"         ğŸ”„ {day_str}: {i + 1}/{len(crash_issues)} í¬ë˜ì‹œ ì´ìŠˆ ì²˜ë¦¬ ì¤‘...")

        # ì´ë²¤íŠ¸ ìˆ˜ ì¡°íšŒ (ì¼ê°„ ë¦¬í¬íŠ¸ì™€ ë™ì¼í•œ ë°©ì‹)
        event_count = get_issue_events_count_optimized(issue, issue_id, start_time, end_time)

        if event_count > 0:
            issue['event_count'] = event_count
            total_events += event_count
            crash_issues_with_events.append(issue)

            # TEST ëª¨ë“œì—ì„œ ìƒì„¸ ì •ë³´ ì¶œë ¥
            if TEST_MODE and len(crash_issues_with_events) <= 3:
                print(f"            âœ… í¬ë˜ì‹œ: {issue.get('title', '')[:40]}")
                print(f"               - ì´ë²¤íŠ¸: {event_count}ê±´")

        # API í˜¸ì¶œ ê°„ ë”œë ˆì´ (rate limit ë°©ì§€)
        if (i + 1) % 10 == 0:
            time.sleep(0.1)

    return total_events


def get_issue_events_count_optimized(issue: Dict, issue_id: str, start_time: datetime, end_time: datetime) -> int:
    """ìµœì í™”ëœ ì´ìŠˆ ì´ë²¤íŠ¸ ìˆ˜ ì¡°íšŒ (ì¼ê°„ ë¦¬í¬íŠ¸ì™€ ì™„ì „ ë™ì¼)"""

    # ìµœì í™” 1: ì´ìŠˆì˜ stats ë°ì´í„° ë¨¼ì € í™•ì¸ (íƒ€ì… ì•ˆì „í•˜ê²Œ)
    try:
        # stats ë°ì´í„° êµ¬ì¡° í™•ì¸ ë° ì•ˆì „í•œ ì²˜ë¦¬
        if 'stats' in issue and issue['stats']:
            stats = issue['stats']

            # 24h ë°ì´í„° í™•ì¸
            if '24h' in stats and stats['24h']:
                stats_24h = stats['24h']

                if TEST_MODE:
                    print(f"         ğŸ” {issue_id}: stats ë°ì´í„° íƒ€ì… í™•ì¸ - {type(stats_24h)}")
                    if isinstance(stats_24h, list) and len(stats_24h) > 0:
                        print(f"         ğŸ” {issue_id}: ì²« ë²ˆì§¸ í•­ëª© - {stats_24h[0]}, íƒ€ì…: {type(stats_24h[0])}")

                recent_count = 0

                # ë‹¤ì–‘í•œ stats í˜•íƒœ ì²˜ë¦¬
                if isinstance(stats_24h, list):
                    for item in stats_24h:
                        try:
                            # itemì´ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš°: [timestamp, count]
                            if isinstance(item, list) and len(item) >= 2:
                                count_value = item[1]
                                if isinstance(count_value, (int, float)) and count_value > 0:
                                    recent_count += int(count_value)
                            # itemì´ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš°
                            elif isinstance(item, dict):
                                for key, value in item.items():
                                    if isinstance(value, (int, float)) and value > 0:
                                        recent_count += int(value)
                            # itemì´ ìˆ«ìì¸ ê²½ìš°
                            elif isinstance(item, (int, float)) and item > 0:
                                recent_count += int(item)
                        except (TypeError, ValueError, IndexError) as e:
                            if TEST_MODE:
                                print(f"         âš ï¸ {issue_id}: stats í•­ëª© ì²˜ë¦¬ ì˜¤ë¥˜ - {e}, í•­ëª©: {item}")
                            continue

                elif isinstance(stats_24h, dict):
                    # statsê°€ ë”•ì…”ë„ˆë¦¬ í˜•íƒœì¸ ê²½ìš°
                    for key, value in stats_24h.items():
                        try:
                            if isinstance(value, (int, float)) and value > 0:
                                recent_count += int(value)
                        except (TypeError, ValueError) as e:
                            if TEST_MODE:
                                print(f"         âš ï¸ {issue_id}: stats dict ì²˜ë¦¬ ì˜¤ë¥˜ - {e}")
                            continue

                if recent_count > 0:
                    if TEST_MODE:
                        print(f"         ğŸ“Š {issue_id}: statsì—ì„œ {recent_count}ê±´ ë°œê²¬ (ë¹ ë¥¸ ë°©ë²•)")
                    return recent_count

        # statsê°€ ì—†ê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•Šìœ¼ë©´ ì´ìŠˆì˜ ê¸°ë³¸ count ì •ë³´ í™œìš©
        total_count = issue.get('count', 0)
        if isinstance(total_count, (int, float)) and total_count > 0:
            # ìµœê·¼ì„± ì¶”ì •: lastSeenì´ íƒ€ê²Ÿ ë‚ ì§œ ë²”ìœ„ ë‚´ì¸ì§€ í™•ì¸
            last_seen_str = issue.get('lastSeen')
            if last_seen_str:
                try:
                    last_seen = datetime.fromisoformat(last_seen_str.replace('Z', '+00:00'))
                    if start_time <= last_seen <= end_time:
                        # ëŒ€ëµì ìœ¼ë¡œ ìµœê·¼ í™œë™ ê¸°ì¤€ìœ¼ë¡œ ì¶”ì •
                        estimated_count = min(int(total_count), 50)  # ìµœëŒ€ 50ê°œë¡œ ì œí•œ
                        if TEST_MODE:
                            print(f"         ğŸ“Š {issue_id}: ì¶”ì • {estimated_count}ê±´ (lastSeen ê¸°ë°˜)")
                        return estimated_count
                except Exception as e:
                    if TEST_MODE:
                        print(f"         âš ï¸ {issue_id}: lastSeen ì²˜ë¦¬ ì˜¤ë¥˜ - {e}")
                    pass

    except Exception as e:
        if TEST_MODE:
            print(f"         âš ï¸ {issue_id} stats ì „ì²´ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            # ë””ë²„ê¹…ì„ ìœ„í•´ stats êµ¬ì¡° ì¶œë ¥
            try:
                stats = issue.get('stats', {})
                print(f"         ğŸ” {issue_id}: stats êµ¬ì¡° - {type(stats)}: {str(stats)[:200]}...")
            except:
                print(f"         ğŸ” {issue_id}: stats êµ¬ì¡° ì¶œë ¥ ì‹¤íŒ¨")

    # ìµœì í™” 2: ì§ì ‘ ì´ë²¤íŠ¸ ì¡°íšŒ (ì œí•œì ìœ¼ë¡œ)
    if TEST_MODE:
        print(f"         ğŸ”„ {issue_id}: ì§ì ‘ ì´ë²¤íŠ¸ ì¡°íšŒë¡œ ì „í™˜")

    return get_issue_events_count_for_date_limited(issue_id, start_time, end_time)


def get_issue_events_count_for_date_limited(issue_id: str, start_time: datetime, end_time: datetime) -> int:
    """ì œí•œì  ì´ë²¤íŠ¸ ìˆ˜ ì¡°íšŒ (ì¼ê°„ ë¦¬í¬íŠ¸ì™€ ì™„ì „ ë™ì¼)"""

    events_url = f"{SENTRY_API_BASE}/issues/{issue_id}/events/"
    all_events = []
    max_pages = 3  # ìµœëŒ€ 3í˜ì´ì§€ë§Œ ì¡°íšŒ (300ê°œ ì´ë²¤íŠ¸)
    page = 0
    cursor = None

    while page < max_pages:
        params = {
            'limit': 100
        }

        if cursor:
            params['cursor'] = cursor

        try:
            response = requests.get(events_url, headers=HEADERS, params=params, timeout=10)  # íƒ€ì„ì•„ì›ƒ ë‹¨ì¶•

            if response.status_code != 200:
                break

            events = response.json()

            if not events:
                break

            # ì‹œê°„ ë²”ìœ„ ë‚´ ì´ë²¤íŠ¸ë§Œ í•„í„°ë§
            found_in_range = False
            for event in events:
                event_time_str = event.get('dateCreated')
                if event_time_str:
                    try:
                        event_time = datetime.fromisoformat(event_time_str.replace('Z', '+00:00'))
                        if start_time <= event_time <= end_time:
                            all_events.append(event)
                            found_in_range = True
                        elif event_time < start_time:
                            # ì‹œê°„ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ë©´ ì¤‘ë‹¨
                            return len(all_events)
                    except:
                        pass

            # í•´ë‹¹ ë²”ìœ„ì— ì´ë²¤íŠ¸ê°€ ì—†ìœ¼ë©´ ì¡°ê¸° ì¤‘ë‹¨
            if not found_in_range and page > 0:
                break

            # ë‹¤ìŒ í˜ì´ì§€ ì²´í¬
            link_header = response.headers.get('Link', '')
            if 'rel="next"' not in link_header:
                break

            cursor_match = re.search(r'cursor=([^&>]+).*rel="next"', link_header)
            if cursor_match:
                cursor = cursor_match.group(1)
                page += 1
            else:
                break

        except requests.exceptions.Timeout:
            if TEST_MODE:
                print(f"         â° {issue_id} ì´ë²¤íŠ¸ ì¡°íšŒ íƒ€ì„ì•„ì›ƒ")
            break
        except Exception as e:
            if TEST_MODE:
                print(f"         âš ï¸ {issue_id} ì´ë²¤íŠ¸ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            break

    return len(all_events)


def get_issue_events_count_for_date_optimized(issue_id: str, start_time: datetime, end_time: datetime) -> int:
    """íŠ¹ì • ì´ìŠˆì˜ íŠ¹ì • ë‚ ì§œ ì´ë²¤íŠ¸ ìˆ˜ ì¡°íšŒ (ì¼ê°„ ë¦¬í¬íŠ¸ ë¡œì§ ìµœì í™”)"""

    events_url = f"{SENTRY_API_BASE}/issues/{issue_id}/events/"
    all_events = []
    cursor = None
    max_pages = 3  # ìµœëŒ€ 3í˜ì´ì§€ë§Œ ì¡°íšŒ

    page = 0
    while page < max_pages:
        params = {
            'limit': 100
        }

        if cursor:
            params['cursor'] = cursor

        try:
            response = requests.get(events_url, headers=HEADERS, params=params, timeout=10)

            if response.status_code != 200:
                break

            events = response.json()

            if not events:
                break

            # ì‹œê°„ ë²”ìœ„ ë‚´ ì´ë²¤íŠ¸ë§Œ í•„í„°ë§
            found_in_range = False
            for event in events:
                event_time_str = event.get('dateCreated')
                if event_time_str:
                    try:
                        event_time = datetime.fromisoformat(event_time_str.replace('Z', '+00:00'))
                        if start_time <= event_time <= end_time:
                            all_events.append(event)
                            found_in_range = True
                        elif event_time < start_time:
                            # ì‹œê°„ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ë©´ ì¤‘ë‹¨
                            return len(all_events)
                    except:
                        pass

            # í•´ë‹¹ ë²”ìœ„ì— ì´ë²¤íŠ¸ê°€ ì—†ìœ¼ë©´ ì¡°ê¸° ì¤‘ë‹¨
            if not found_in_range and page > 0:
                break

            # ë‹¤ìŒ í˜ì´ì§€ ì²´í¬
            link_header = response.headers.get('Link', '')
            if 'rel="next"' not in link_header:
                break

            cursor_match = re.search(r'cursor=([^&>]+).*rel="next"', link_header)
            if cursor_match:
                cursor = cursor_match.group(1)
                page += 1
            else:
                break

        except requests.exceptions.Timeout:
            break
        except Exception as e:
            break

    return len(all_events)


def detect_anomalies_simple(this_week_daily: List[int]) -> List[str]:
    """ê°„ë‹¨í•œ ì´ìƒ ì§•í›„ íƒì§€ (ì „ì£¼ ë¹„êµ ì œê±°)"""
    anomalies = []

    if not this_week_daily or len(this_week_daily) < 7:
        return anomalies

    avg_crashes = sum(this_week_daily) / len(this_week_daily)
    days = ['ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† ', 'ì¼']

    for i, crashes in enumerate(this_week_daily):
        day_name = days[i]

        # ê¸‰ì¦ ê°ì§€ (í‰ê·  ëŒ€ë¹„ 100% ì´ìƒ)
        if avg_crashes > 0 and crashes > avg_crashes * 2:
            anomalies.append(f"{day_name}ìš”ì¼ ê¸‰ì¦: {crashes}ê±´ (ì´ë²ˆì£¼ í‰ê·  {avg_crashes:.0f}ê±´ ëŒ€ë¹„ +{((crashes/avg_crashes-1)*100):.0f}%)")

        # ì„ê³„ì  ëŒíŒŒ (ì¼ 100ê±´ ì´ˆê³¼)
        if crashes > 100:
            anomalies.append(f"{day_name}ìš”ì¼ ì„ê³„ì  ëŒíŒŒ: {crashes}ê±´ (ê¸°ì¤€: 100ê±´)")

    # ì—°ì† ì¦ê°€ íŒ¨í„´ ê°ì§€
    consecutive_increases = 0
    for i in range(1, len(this_week_daily)):
        if this_week_daily[i] > this_week_daily[i-1]:
            consecutive_increases += 1
        else:
            if consecutive_increases >= 2:  # 3ì¼ ì´ìƒ ì—°ì† ì¦ê°€
                end_day = days[i-1]
                start_day = days[i-consecutive_increases-1]
                start_count = this_week_daily[i-consecutive_increases-1]
                end_count = this_week_daily[i-1]
                anomalies.append(f"{start_day}-{end_day} ì—°ì† ì¦ê°€: {start_count}ê±´ â†’ {end_count}ê±´ ({consecutive_increases+1}ì¼ê°„)")
            consecutive_increases = 0

    # ë§ˆì§€ë§‰ ì²´í¬
    if consecutive_increases >= 2:
        end_day = days[-1]
        start_day = days[-consecutive_increases-2]
        start_count = this_week_daily[-consecutive_increases-2]
        end_count = this_week_daily[-1]
        anomalies.append(f"{start_day}-{end_day} ì—°ì† ì¦ê°€: {start_count}ê±´ â†’ {end_count}ê±´ ({consecutive_increases+1}ì¼ê°„)")

    return anomalies


def analyze_issue_lifecycle_improved(this_week_issues: List[Dict], prev_week_issues: List[Dict],
                                   this_week_start: datetime) -> Dict:
    """ê°œì„ ëœ ì´ìŠˆ ìƒëª…ì£¼ê¸° ë¶„ì„ (ì§„ì§œ ì‹ ê·œ ì´ìŠˆ íŒë³„)"""
    # ì´ìŠˆë¥¼ IDë¡œ ë§¤í•‘
    this_week_map = {issue['id']: issue for issue in this_week_issues}
    prev_week_map = {issue['id']: issue for issue in prev_week_issues}

    this_week_ids = set(this_week_map.keys())
    prev_week_ids = set(prev_week_map.keys())

    # ì§„ì§œ ì‹ ê·œ ì´ìŠˆ (firstSeenì´ ì´ë²ˆ ì£¼ ë²”ìœ„ ë‚´)
    new_issues = []
    for issue_id in this_week_ids:
        issue = this_week_map[issue_id]
        first_seen_str = issue.get('firstSeen')

        if first_seen_str:
            try:
                first_seen = datetime.fromisoformat(first_seen_str.replace('Z', '+00:00'))
                # ì´ë²ˆ ì£¼ì— ì²˜ìŒ ë°œìƒí•œ ì´ìŠˆë§Œ ì‹ ê·œë¡œ ë¶„ë¥˜
                if first_seen >= this_week_start.astimezone(timezone.utc):
                    count = issue.get('weekly_event_count', 0)
                    if count > 0:
                        new_issues.append({
                            'issue': issue,
                            'count': count,
                            'first_seen': first_seen
                        })
            except:
                pass

    new_issues.sort(key=lambda x: x['count'], reverse=True)

    # ì•…í™”ëœ ì´ìŠˆ (ì „ì£¼ì—ë„ ìˆì—ˆê³  ì´ë²ˆì£¼ì—ë„ ìˆìœ¼ë©´ì„œ 50% ì´ìƒ ì¦ê°€)
    worsened_issues = []
    for issue_id in this_week_ids & prev_week_ids:
        this_count = this_week_map[issue_id].get('weekly_event_count', 0)
        prev_count = prev_week_map[issue_id].get('weekly_event_count', 0)

        if prev_count > 0 and this_count > prev_count * 1.5:  # 50% ì´ìƒ ì¦ê°€
            increase_rate = ((this_count - prev_count) / prev_count) * 100
            worsened_issues.append({
                'issue': this_week_map[issue_id],
                'this_count': this_count,
                'prev_count': prev_count,
                'increase_rate': increase_rate
            })
    worsened_issues.sort(key=lambda x: x['increase_rate'], reverse=True)

    # ê°œì„ ëœ ì´ìŠˆ
    improved_issues = []
    for issue_id in this_week_ids & prev_week_ids:
        this_count = this_week_map[issue_id].get('weekly_event_count', 0)
        prev_count = prev_week_map[issue_id].get('weekly_event_count', 0)

        if prev_count > 0 and this_count < prev_count * 0.5:  # 50% ì´ìƒ ê°ì†Œ
            decrease_rate = ((prev_count - this_count) / prev_count) * 100
            improved_issues.append({
                'issue': this_week_map[issue_id],
                'this_count': this_count,
                'prev_count': prev_count,
                'decrease_rate': decrease_rate
            })
    improved_issues.sort(key=lambda x: x['decrease_rate'], reverse=True)

    # í•´ê²°ëœ ì´ìŠˆ
    resolved_issues = []
    for issue_id in prev_week_ids - this_week_ids:
        prev_issue = prev_week_map[issue_id]
        prev_count = prev_issue.get('weekly_event_count', 0)
        if prev_count >= 10:  # ì „ì£¼ì— 10ê±´ ì´ìƒì´ì—ˆë˜ ì´ìŠˆë§Œ
            resolved_issues.append({
                'issue': prev_issue,
                'prev_count': prev_count
            })
    resolved_issues.sort(key=lambda x: x['prev_count'], reverse=True)

    return {
        'new': new_issues[:5],
        'worsened': worsened_issues[:5],
        'improved': improved_issues[:5],
        'resolved': resolved_issues[:5]
    }


def get_weekly_crash_free_rate():
    """ì£¼ê°„ Crash-Free Rate ì¡°íšŒ"""
    sessions_url = f"{SENTRY_API_BASE}/organizations/{ORG_SLUG}/sessions/"

    end_time = datetime.now(timezone.utc)
    start_time = end_time - timedelta(days=7)

    params = {
        'field': ['crash_free_rate(session)'],
        'start': start_time.isoformat(),
        'end': end_time.isoformat(),
        'project': [PROJECT_ID],
        'environment': [ENVIRONMENT],
        'totals': 1
    }

    try:
        response = requests.get(sessions_url, headers=HEADERS, params=params, timeout=30)

        if response.status_code == 200:
            data = response.json()

            if 'groups' in data and data['groups']:
                for group in data['groups']:
                    totals = group.get('totals', {})
                    session_crash_free = totals.get('crash_free_rate(session)')

                    if session_crash_free is not None:
                        rate = session_crash_free * 100 if session_crash_free <= 1 else session_crash_free
                        return f"{rate:.2f}%"

    except Exception as e:
        if TEST_MODE:
            print(f"   âŒ ì£¼ê°„ Crash-Free Rate ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")

    return "N/A"


def safe_int(value, default=0):
    """ì•ˆì „í•œ ì •ìˆ˜ ë³€í™˜"""
    try:
        if isinstance(value, (int, float)):
            return int(value)
        elif isinstance(value, str) and value.isdigit():
            return int(value)
        else:
            return default
    except (ValueError, TypeError):
        return default


def format_issue_title(title: str, max_length: int = 40) -> str:
    """ì´ìŠˆ ì œëª© í¬ë§·íŒ…"""
    if len(title) > max_length:
        title = title[:max_length - 3] + "..."

    # Slack íŠ¹ìˆ˜ ë¬¸ì ì²˜ë¦¬
    title = title.replace('*', '').replace('_', '').replace('`', '')
    return title


def format_weekly_slack_message(this_week_stats: Dict, prev_week_stats: Dict, lifecycle: Dict,
                                anomalies: List[str], crash_free_rate: str, week_info: Dict,
                                this_week_daily: List[int]) -> Dict:
    """ì£¼ê°„ Slack ë©”ì‹œì§€ í¬ë§·íŒ… (ìš”ì¼ë³„ í¬ë˜ì‹œ ì •ë³´ í¬í•¨)"""

    this_week_start_kst = week_info['this_week'][2]
    this_week_end_kst = this_week_start_kst + timedelta(days=6)

    week_range = f"{this_week_start_kst.strftime('%Yë…„ %mì›” %dì¼')} ~ {this_week_end_kst.strftime('%mì›” %dì¼')}"

    # ì „ì£¼ ëŒ€ë¹„ ë³€í™” ê³„ì‚°
    current = this_week_stats['total_crashes']
    previous = prev_week_stats['total_crashes']

    change_text = ""
    if previous == 0 and current == 0:
        change_text = " (ë³€í™” ì—†ìŒ â¡ï¸)"
        status_color = "good"
        main_emoji = "âœ¨"
        status_text = "ì•ˆì •ì "
    elif previous == 0:
        change_text = " (ì‹ ê·œ ë°œìƒ ğŸš¨)"
        status_color = "danger"
        main_emoji = "ğŸš¨"
        status_text = "ì£¼ì˜ í•„ìš”"
    elif current == 0:
        change_text = " (ì™„ì „ í•´ê²° ğŸ‰)"
        status_color = "good"
        main_emoji = "ğŸ‰"
        status_text = "ì™„ë²½!"
    else:
        change_count = current - previous
        if change_count > 0:
            change_text = f" (ì „ì£¼ ëŒ€ë¹„ +{change_count}ê±´ ğŸ“ˆ)"
            status_color = "warning" if change_count < 100 else "danger"
            main_emoji = "âš ï¸" if change_count < 100 else "ğŸš¨"
            status_text = "ì¦ê°€" if change_count < 100 else "ê¸‰ì¦"
        elif change_count < 0:
            change_text = f" (ì „ì£¼ ëŒ€ë¹„ {change_count}ê±´ ğŸ“‰)"
            status_color = "good"
            main_emoji = "âœ…"
            status_text = "ê°œì„ "
        else:
            change_text = " (ì „ì£¼ì™€ ë™ì¼ â¡ï¸)"
            status_color = "good"
            main_emoji = "â¡ï¸"
            status_text = "ì•ˆì •ì "

    # ì¼í‰ê·  ê³„ì‚°
    daily_avg = current // 7 if current > 0 else 0

    # ìš”ì¼ë³„ í¬ë˜ì‹œ í˜„í™© í…ìŠ¤íŠ¸ ìƒì„± (ë‹´ë°±í•˜ê²Œ ìˆ«ìë§Œ)
    days = ['ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† ', 'ì¼']
    daily_text = ""

    for i, (day, count) in enumerate(zip(days, this_week_daily)):
        daily_text += f"{day} {count}ê±´ "

    test_indicator = " [í…ŒìŠ¤íŠ¸]" if TEST_MODE else ""

    # ê¸°ë³¸ ë¸”ë¡ë“¤
    blocks = [
        {
            "type": "header",
            "text": {
                "type": "plain_text",
                "text": f"Android ì£¼ê°„ í¬ë˜ì‹œ ë¦¬í¬íŠ¸{test_indicator}",
                "emoji": True
            }
        },
        {
            "type": "context",
            "elements": [
                {
                    "type": "mrkdwn",
                    "text": f"ğŸ“… {week_range} | ğŸŒ {ENVIRONMENT} | ìƒíƒœ: {main_emoji} {status_text}"
                }
            ]
        },
        {
            "type": "divider"
        },
        {
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": f"*ğŸ“Š ì£¼ìš” ì§€í‘œ*"
            }
        },
        {
            "type": "section",
            "fields": [
                {
                    "type": "mrkdwn",
                    "text": f"*ì£¼ê°„ ì´ í¬ë˜ì‹œ*\n{current:,}ê±´ (ì¼í‰ê·  {daily_avg}ê±´){change_text}"
                },
                {
                    "type": "mrkdwn",
                    "text": f"*ì˜í–¥ë°›ì€ ì‚¬ìš©ì*\n{this_week_stats['affected_users']:,}ëª…"
                },
                {
                    "type": "mrkdwn",
                    "text": f"*í¬ë˜ì‹œ ì´ìŠˆ ì¢…ë¥˜*\n{this_week_stats['total_issues']}ê°œ"
                },
                {
                    "type": "mrkdwn",
                    "text": f"*ì£¼ê°„ Crash-Free Rate*\n{crash_free_rate}"
                }
            ]
        },
        {
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": f"*ğŸ“ˆ ìš”ì¼ë³„ í¬ë˜ì‹œ í˜„í™©*\n{daily_text.strip()}"
            }
        }
    ]

    # ì´ìƒ ì§•í›„ ì„¹ì…˜ (ì¡°ê±´ë¶€)
    if anomalies:
        blocks.extend([
            {
                "type": "divider"
            },
            {
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": f"*âš ï¸ ì´ë²ˆ ì£¼ ì´ìƒ ì§•í›„ ê°ì§€*\n" + "\n".join([f"â€¢ {anomaly}" for anomaly in anomalies[:3]])
                }
            }
        ])

    # ì´ìŠˆ ìƒëª…ì£¼ê¸° ì„¹ì…˜
    lifecycle_text = ""

    if lifecycle['new']:
        lifecycle_text += f"ğŸ†• *ì‹ ê·œ ë°œìƒ ({len(lifecycle['new'])}ê°œ)*\n"
        for i, item in enumerate(lifecycle['new'][:3], 1):
            title = format_issue_title(item['issue'].get('title', 'Unknown'))
            count = item['count']
            first_seen = item.get('first_seen')
            if first_seen:
                first_seen_kst = first_seen.astimezone(KST)
                date_str = first_seen_kst.strftime('%m/%d')
                lifecycle_text += f"  {i}. {title} - {count}ê±´ ({date_str} ì²« ë°œìƒ)\n"
            else:
                lifecycle_text += f"  {i}. {title} - {count}ê±´\n"
        lifecycle_text += "\n"

    if lifecycle['worsened']:
        lifecycle_text += f"âš ï¸ *ì•…í™” ({len(lifecycle['worsened'])}ê°œ)*\n"
        for i, item in enumerate(lifecycle['worsened'][:2], 1):
            title = format_issue_title(item['issue'].get('title', 'Unknown'))
            rate = item['increase_rate']
            lifecycle_text += f"  {i}. {title} +{rate:.0f}% ({item['prev_count']}â†’{item['this_count']}ê±´)\n"
        lifecycle_text += "\n"

    if lifecycle['improved']:
        lifecycle_text += f"âœ… *ê°œì„  ({len(lifecycle['improved'])}ê°œ)*\n"
        for i, item in enumerate(lifecycle['improved'][:2], 1):
            title = format_issue_title(item['issue'].get('title', 'Unknown'))
            rate = item['decrease_rate']
            lifecycle_text += f"  {i}. {title} -{rate:.0f}% ({item['prev_count']}â†’{item['this_count']}ê±´)\n"
        lifecycle_text += "\n"

    if lifecycle['resolved']:
        lifecycle_text += f"ğŸ‰ *í•´ê²° ì™„ë£Œ ({len(lifecycle['resolved'])}ê°œ)*\n"
        for i, item in enumerate(lifecycle['resolved'][:2], 1):
            title = format_issue_title(item['issue'].get('title', 'Unknown'))
            prev_count = item['prev_count']
            lifecycle_text += f"  {i}. {title} (ì „ì£¼ {prev_count}ê±´ â†’ í•´ê²°)\n"

    if not lifecycle_text:
        lifecycle_text = "ì´ë²ˆ ì£¼ëŠ” íŠ¹ë³„í•œ ë³€í™”ê°€ ì—†ì—ˆìŠµë‹ˆë‹¤."

    blocks.extend([
        {
            "type": "divider"
        },
        {
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": f"*ğŸ”„ ì´ìŠˆ ìƒëª…ì£¼ê¸° ë¶„ì„*\n{lifecycle_text}"
            }
        }
    ])

    # ëŒ€ì‹œë³´ë“œ ë§í¬
    dashboard_url = f"https://finda-b2c.sentry.io/dashboard/{DASH_BOARD_ID}" if DASH_BOARD_ID else "https://finda-b2c.sentry.io/dashboards"
    button_text = "Sentry ëŒ€ì‹œë³´ë“œ ì—´ê¸°" if DASH_BOARD_ID else "Sentry ëŒ€ì‹œë³´ë“œ ëª©ë¡ ì—´ê¸°"

    blocks.extend([
        {
            "type": "actions",
            "elements": [
                {
                    "type": "button",
                    "text": {
                        "type": "plain_text",
                        "text": button_text,
                        "emoji": True
                    },
                    "url": dashboard_url,
                    "style": "primary"
                }
            ]
        },
        {
            "type": "context",
            "elements": [
                {
                    "type": "mrkdwn",
                    "text": f"_{'ë¡œì»¬ í…ŒìŠ¤íŠ¸' if TEST_MODE else 'GitHub Actions'}ì—ì„œ ìƒì„±ë¨_"
                }
            ]
        }
    ])

    return {
        "attachments": [
            {
                "color": status_color,
                "blocks": blocks
            }
        ]
    }


def send_to_slack(message: Dict) -> bool:
    """Slackìœ¼ë¡œ ë©”ì‹œì§€ ì „ì†¡"""
    if not SLACK_WEBHOOK:
        print("âš ï¸  SLACK_WEBHOOK_URLì´ ì„¤ì •ë˜ì§€ ì•Šì•„ Slack ì „ì†¡ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return True

    if TEST_MODE:
        print("ğŸ” í…ŒìŠ¤íŠ¸ ëª¨ë“œ - ì£¼ê°„ Slack ë©”ì‹œì§€ ë‚´ìš©:")
        print(json.dumps(message, indent=2, ensure_ascii=False))
        print("\nğŸ’¡ ì‹¤ì œ ì „ì†¡í•˜ë ¤ë©´ TEST_MODE=falseë¡œ ì„¤ì •í•˜ì„¸ìš”.")
        return True

    try:
        response = requests.post(SLACK_WEBHOOK, json=message)

        if response.status_code == 200:
            print("âœ… ì£¼ê°„ Slack ë©”ì‹œì§€ ì „ì†¡ ì„±ê³µ")
            return True
        else:
            print(f"âŒ ì£¼ê°„ Slack ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨: {response.status_code}")
            print(f"Response: {response.text}")
            return False
    except Exception as e:
        print(f"âŒ ì£¼ê°„ Slack ì „ì†¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return False


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        print("ğŸš€ ì£¼ê°„ í¬ë˜ì‹œ ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘...")

        if TEST_MODE:
            print("ğŸ§ª ì£¼ê°„ ë¦¬í¬íŠ¸ í…ŒìŠ¤íŠ¸ ëª¨ë“œë¡œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.")

        # ì£¼ê°„ ë‚ ì§œ ë²”ìœ„ ê³„ì‚°
        week_info = get_weekly_datetime_range()
        this_week_start_utc, this_week_end_utc, this_week_start_kst = week_info['this_week']
        prev_week_start_utc, prev_week_end_utc, prev_week_start_kst = week_info['prev_week']

        this_week_str = this_week_start_kst.strftime('%Y-%m-%d')
        prev_week_str = prev_week_start_kst.strftime('%Y-%m-%d')

        print(f"ğŸ“… ì´ë²ˆ ì£¼: {this_week_str} ~ {(this_week_start_kst + timedelta(days=6)).strftime('%Y-%m-%d')} (KST)")
        print(f"ğŸ“… ì „ì£¼: {prev_week_str} ~ {(prev_week_start_kst + timedelta(days=6)).strftime('%Y-%m-%d')} (KST)")

        # Sentry ì—°ê²° í…ŒìŠ¤íŠ¸ (TEST_MODEì¼ ë•Œë§Œ)
        if TEST_MODE:
            print("\nğŸ” Sentry ì—°ê²° í…ŒìŠ¤íŠ¸...")
            test_url = f"{SENTRY_API_BASE}/projects/{ORG_SLUG}/{PROJECT_SLUG}/"
            test_response = requests.get(test_url, headers=HEADERS)

            if test_response.status_code == 200:
                project_info = test_response.json()
                print(f"âœ… Sentry ì—°ê²° ì„±ê³µ: {project_info.get('name')} ({project_info.get('platform')})")
            else:
                print(f"âŒ Sentry ì—°ê²° ì‹¤íŒ¨: {test_response.status_code}")
                return

        # ì´ë²ˆ ì£¼ ë°ì´í„° ìˆ˜ì§‘
        print("\nğŸ“Š ì´ë²ˆ ì£¼ Sentry ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
        this_week_issues = collect_weekly_issues(this_week_start_utc, this_week_end_utc, "ì´ë²ˆì£¼")
        this_week_stats = calculate_weekly_crash_stats(this_week_issues, this_week_start_utc, this_week_end_utc, "ì´ë²ˆì£¼")

        # ì „ì£¼ ë°ì´í„° ìˆ˜ì§‘
        print("\nğŸ“Š ì „ì£¼ Sentry ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
        prev_week_issues = collect_weekly_issues(prev_week_start_utc, prev_week_end_utc, "ì „ì£¼")
        prev_week_stats = calculate_weekly_crash_stats(prev_week_issues, prev_week_start_utc, prev_week_end_utc, "ì „ì£¼")

        print(f"\nğŸ“ˆ ìˆ˜ì§‘ ê²°ê³¼:")
        print(f"  - ì´ë²ˆ ì£¼ í¬ë˜ì‹œ: {this_week_stats['total_crashes']}ê±´")
        print(f"  - ì „ì£¼ í¬ë˜ì‹œ: {prev_week_stats['total_crashes']}ê±´")
        print(f"  - ì´ë²ˆ ì£¼ ì´ìŠˆ: {this_week_stats['total_issues']}ê°œ")
        print(f"  - ì´ë²ˆ ì£¼ ì˜í–¥ ì‚¬ìš©ì: {this_week_stats['affected_users']}ëª…")

        # ì´ìƒ ì§•í›„ íƒì§€ (ì¼ê°„ ë¦¬í¬íŠ¸ ë¡œì§ ì‚¬ìš©)
        print("\nğŸ” ì¼ë³„ í¬ë˜ì‹œ ë°ì´í„° ìˆ˜ì§‘ ë° ì´ìƒ ì§•í›„ íƒì§€ ì¤‘...")
        this_week_daily = collect_daily_crash_data_simple(this_week_start_utc)
        anomalies = detect_anomalies_simple(this_week_daily)

        print(f"ğŸ“Š ì´ë²ˆì£¼ ì¼ë³„ í¬ë˜ì‹œ: {this_week_daily}")

        if anomalies:
            print(f"âš ï¸ {len(anomalies)}ê°œ ì´ìƒ ì§•í›„ ê°ì§€:")
            for anomaly in anomalies:
                print(f"  - {anomaly}")
        else:
            print("âœ… ì´ìƒ ì§•í›„ ì—†ìŒ")

        # ì´ìŠˆ ìƒëª…ì£¼ê¸° ë¶„ì„ (ê°œì„ ëœ ë²„ì „)
        print("\nğŸ”„ ì´ìŠˆ ìƒëª…ì£¼ê¸° ë¶„ì„ ì¤‘...")
        lifecycle = analyze_issue_lifecycle_improved(this_week_stats['issues'], prev_week_stats['issues'], this_week_start_kst)

        print(f"  - ì§„ì§œ ì‹ ê·œ ì´ìŠˆ: {len(lifecycle['new'])}ê°œ")
        print(f"  - ì•…í™” ì´ìŠˆ: {len(lifecycle['worsened'])}ê°œ")
        print(f"  - ê°œì„  ì´ìŠˆ: {len(lifecycle['improved'])}ê°œ")
        print(f"  - í•´ê²° ì´ìŠˆ: {len(lifecycle['resolved'])}ê°œ")

        # ì£¼ê°„ Crash-Free Rate ì¡°íšŒ
        print("\nğŸ“Š ì£¼ê°„ Crash-Free Rate ì¡°íšŒ ì¤‘...")
        crash_free_rate = get_weekly_crash_free_rate()
        print(f"  - ì£¼ê°„ Crash-Free Rate: {crash_free_rate}")

        # ìŠ¬ë™ ë©”ì‹œì§€ ìƒì„±
        print("\nğŸ“ ì£¼ê°„ ë¦¬í¬íŠ¸ ë©”ì‹œì§€ ìƒì„± ì¤‘...")
        message = format_weekly_slack_message(
            this_week_stats, prev_week_stats, lifecycle,
            anomalies, crash_free_rate, week_info,
            this_week_daily
        )

        # Slack ì „ì†¡
        print("\nğŸ“¤ Slackìœ¼ë¡œ ì „ì†¡ ì¤‘...")
        success = send_to_slack(message)

        if success:
            print("\nğŸ‰ ì£¼ê°„ í¬ë˜ì‹œ ë¦¬í¬íŠ¸ ì „ì†¡ ì™„ë£Œ!")

            # ì‹¬ê°í•œ ìƒí™© ì•Œë¦¼
            if this_week_stats['total_crashes'] > 500:
                print("âš ï¸ ì£¼ê°„ í¬ë˜ì‹œê°€ 500ê±´ì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì¦‰ì‹œ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤!")
            elif anomalies:
                print("âš ï¸ ì´ìƒ ì§•í›„ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ìƒì„¸ ë¶„ì„ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
        else:
            print("\nâŒ ì£¼ê°„ ë¦¬í¬íŠ¸ ì „ì†¡ ì‹¤íŒ¨")
            exit(1)

    except Exception as e:
        print(f"\nğŸ’¥ ì£¼ê°„ ë¦¬í¬íŠ¸ ìƒì„± ì˜¤ë¥˜: {str(e)}")

        if TEST_MODE:
            import traceback
            print("\nìƒì„¸ ì˜¤ë¥˜ ì •ë³´:")
            traceback.print_exc()

        # ì˜¤ë¥˜ ì•Œë¦¼ë„ Slackìœ¼ë¡œ ì „ì†¡
        if SLACK_WEBHOOK and not TEST_MODE:
            error_message = {
                "text": f"ğŸš¨ ì£¼ê°„ í¬ë˜ì‹œ ë¦¬í¬íŠ¸ ìƒì„± ì˜¤ë¥˜: {str(e)}",
                "blocks": [
                    {
                        "type": "section",
                        "text": {
                            "type": "mrkdwn",
                            "text": f"*ğŸš¨ ì£¼ê°„ í¬ë˜ì‹œ ë¦¬í¬íŠ¸ ìƒì„± ì˜¤ë¥˜*\n\n"
                                    f"â€¢ ì˜¤ë¥˜: `{str(e)}`\n"
                                    f"â€¢ ì‹œê°„: {datetime.now(KST).strftime('%Y-%m-%d %H:%M:%S')} KST\n"
                                    f"â€¢ í™˜ê²½: {'ë¡œì»¬ í…ŒìŠ¤íŠ¸' if TEST_MODE else 'GitHub Actions'}"
                        }
                    }
                ]
            }

            if not TEST_MODE:
                error_message["blocks"][0]["text"]["text"] += f"\nâ€¢ ì €ì¥ì†Œ: `{os.getenv('GITHUB_REPOSITORY', 'unknown')}`"
                error_message["blocks"].append({
                    "type": "actions",
                    "elements": [
                        {
                            "type": "button",
                            "text": {
                                "type": "plain_text",
                                "text": "GitHub Actions ë¡œê·¸ í™•ì¸"
                            },
                            "url": f"https://github.com/{os.getenv('GITHUB_REPOSITORY', '')}/actions"
                        }
                    ]
                })

            send_to_slack(error_message)

        exit(1)


if __name__ == "__main__":
    main()
#!/usr/bin/env python3
import argparse
import datetime as dt
import json
import os
import re
from typing import Any, Dict, List, Optional, Tuple

import requests
from dotenv import load_dotenv

# ------ Optional OpenAI ------
try:
    from openai import OpenAI  # pip install openai
except Exception:
    OpenAI = None

# ==============================
# í™˜ê²½ ë³€ìˆ˜
# ==============================
load_dotenv()

SENTRY_API_BASE = os.getenv("SENTRY_API_BASE", "https://sentry.io/api/0")
SENTRY_AUTH_TOKEN = os.getenv("SENTRY_AUTH_TOKEN")
SENTRY_ORG_SLUG = os.getenv("SENTRY_ORG_SLUG")
SENTRY_PROJECT_SLUG = os.getenv("SENTRY_PROJECT_SLUG")
SENTRY_PROJECT_ID = os.getenv("SENTRY_PROJECT_ID")
SENTRY_ENVIRONMENT = os.getenv("SENTRY_ENVIRONMENT", "production")

SLACK_WEBHOOK_URL = os.getenv("SLACK_WEBHOOK_URL", "")
TEST_MODE = os.getenv("TEST_MODE", "true").lower() == "true"  # true=ë¯¸ì „ì†¡, false=ì „ì†¡

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
AI_MODEL = os.getenv("AI_MODEL", "gpt-4o-mini")
DEFAULT_MAX_ITEMS = int(os.getenv("MAX_ITEMS_PER_CATEGORY", "5"))

client = OpenAI(api_key=OPENAI_API_KEY) if (OPENAI_API_KEY and OpenAI) else None

# ==============================
# ì‹œê°„ ìœ í‹¸ (KST â†” UTC)
# ==============================
KST = dt.timezone(dt.timedelta(hours=9))
UTC = dt.timezone.utc

def kst_today() -> dt.date:
    return (dt.datetime.utcnow() + dt.timedelta(hours=9)).date()

def y_and_dby(date_opt: Optional[str]) -> Tuple[str, str]:
    """
    --date ê°€ ìˆìœ¼ë©´ ê·¸ ë‚ ì§œë¥¼ 'ì–´ì œ'ë¡œ ê°„ì£¼. ì—†ìœ¼ë©´ ì‹¤ì œ ì–´ì œ/ê·¸ì œ(KST).
    ë°˜í™˜: ('YYYY-MM-DD', 'YYYY-MM-DD')
    """
    if date_opt:
        y = dt.datetime.strptime(date_opt, "%Y-%m-%d").date()
        dby = y - dt.timedelta(days=1)
    else:
        today = kst_today()
        y = today - dt.timedelta(days=1)
        dby = today - dt.timedelta(days=2)
    return y.strftime("%Y-%m-%d"), dby.strftime("%Y-%m-%d")

def kst_day_to_utc_range(day_str: str) -> Tuple[str, str]:
    """'YYYY-MM-DD'(KST)ì˜ í•˜ë£¨ â†’ UTC ISO8601 Z ë²”ìœ„"""
    y, m, d = map(int, day_str.split("-"))
    start_kst = dt.datetime(y, m, d, 0, 0, 0, tzinfo=KST)
    end_kst   = dt.datetime(y, m, d, 23, 59, 59, tzinfo=KST)
    start_utc = start_kst.astimezone(UTC).isoformat().replace("+00:00", "Z")
    end_utc   = end_kst.astimezone(UTC).isoformat().replace("+00:00", "Z")
    return start_utc, end_utc

# ==============================
# Sentry API ê³µí†µ
# ==============================
def _auth_headers() -> Dict[str, str]:
    if not SENTRY_AUTH_TOKEN:
        raise RuntimeError("Missing SENTRY_AUTH_TOKEN")
    return {"Authorization": f"Bearer {SENTRY_AUTH_TOKEN}"}

def _get(path: str, params: Optional[Dict[str, Any]] = None) -> Any:
    url = f"{SENTRY_API_BASE}{path}"
    resp = requests.get(url, headers=_auth_headers(), params=params, timeout=30)
    try:
        resp.raise_for_status()
    except requests.HTTPError as e:
        raise requests.HTTPError(f"{e} | url={resp.url} | body={resp.text}") from e
    return resp.json()

# ==============================
# Issues: í˜ì´ì§€ë„¤ì´ì…˜ ì „ì²´ ì¡°íšŒ
# ==============================
def fetch_issues_all(start_kst: str, end_kst: str) -> List[Dict[str, Any]]:
    """
    Issues APIì—ì„œ KST í•˜ë£¨ ë²”ìœ„ì˜ ì´ìŠˆ 'ì „ëŸ‰' ì¡°íšŒ (per_page=100 + cursor).
    """
    path = f"/projects/{SENTRY_ORG_SLUG}/{SENTRY_PROJECT_SLUG}/issues/"
    url = f"{SENTRY_API_BASE}{path}"
    headers = _auth_headers()
    params = {
        "start": f"{start_kst}T00:00:00",
        "end": f"{end_kst}T23:59:59",
        "project": SENTRY_PROJECT_ID,
        "environment": SENTRY_ENVIRONMENT,
        "statsPeriod": "",
        "per_page": 100,
        # ì •ë ¬ ê¸°ë³¸: ìµœê·¼ ë°œìƒ(ê¸°ë³¸) or freq, priority ë“± í•„ìš”ì‹œ ë³€ê²½
    }

    items: List[Dict[str, Any]] = []
    cursor = None
    while True:
        if cursor:
            params["cursor"] = cursor
        r = requests.get(url, headers=headers, params=params, timeout=30)
        r.raise_for_status()
        batch = r.json()
        if not isinstance(batch, list):
            break
        items.extend(batch)

        link = r.headers.get("Link", "")
        m = re.search(r'<[^>]+cursor="([^"]+)">;\s*rel="next";\s*results="(true|false)"', link)
        if not m or m.group(2) != "true":
            break
        cursor = m.group(1)
    return items

# ==============================
# Crash-Free (Sessions API)
# ==============================
def fetch_crash_free_rates_kst(day_kst: str) -> Dict[str, float]:
    """
    Sessions APIì—ì„œ Crash-Free ë¹„ìœ¨(ì–´ì œ KST í•˜ë£¨)ì„ %ë¡œ ë°˜í™˜.
    1ì°¨: statsPeriod=1d + field=crash_free_rate(session|user)
    2ì°¨: start/end + interval=1h + field=...
    """
    start_utc_iso, end_utc_iso = kst_day_to_utc_range(day_kst)
    path = f"/organizations/{SENTRY_ORG_SLUG}/sessions/"

    def parse_rate(val: Optional[float]) -> Optional[float]:
        if val is None:
            return None
        return round(val * 100.0, 3)  # 0~1 â†’ %

    def try_request(params: Dict[str, Any]) -> Dict[str, float]:
        data = _get(path, params=params)
        totals = data.get("totals") or {}
        s_rate = totals.get("crash_free_rate(session)")
        u_rate = totals.get("crash_free_rate(user)")
        # groups fallback
        if s_rate is None or u_rate is None:
            for g in data.get("groups", []):
                t = g.get("totals") or {}
                if s_rate is None:
                    s_rate = t.get("crash_free_rate(session)", s_rate)
                if u_rate is None:
                    u_rate = t.get("crash_free_rate(user)", u_rate)
        s_pct = parse_rate(s_rate) if s_rate is not None else None
        u_pct = parse_rate(u_rate) if u_rate is not None else None
        if s_pct is None and u_pct is None:
            raise ValueError("No crash_free_rate(session|user) in response")
        return {
            "crash_free_sessions_pct": s_pct if s_pct is not None else 100.0,
            "crash_free_users_pct":    u_pct if u_pct is not None else 100.0,
        }

    # A) statsPeriod=1d
    try:
        params_a = {
            "project": SENTRY_PROJECT_ID,
            "environment": SENTRY_ENVIRONMENT,
            "statsPeriod": "1d",
            "field": ["crash_free_rate(session)", "crash_free_rate(user)"],
            "includeTotals": 1,
            "includeSeries": 0,
        }
        return try_request(params_a)
    except requests.HTTPError:
        pass

    # B) start/end + interval
    params_b = {
        "project": SENTRY_PROJECT_ID,
        "environment": SENTRY_ENVIRONMENT,
        "start": start_utc_iso,
        "end": end_utc_iso,
        "interval": "1h",
        "field": ["crash_free_rate(session)", "crash_free_rate(user)"],
        "includeTotals": 1,
        "includeSeries": 0,
    }
    return try_request(params_b)

# ==============================
# ë¶„ë¥˜/ì§€í‘œ
# ==============================
def classify_issues(yesterday: List[Dict[str, Any]], day_before: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:
    high = [i for i in yesterday if i.get("level") in ("fatal", "error")]
    new  = [i for i in yesterday if i.get("isNew")]
    prev_map = {i["id"]: i for i in day_before if i.get("id")}

    spike: List[Dict[str, Any]] = []
    for yi in yesterday:
        y_cnt = int(yi.get("count", 0) or 0)
        prev  = prev_map.get(yi.get("id"))
        if prev:
            d_cnt = int(prev.get("count", 0) or 0)
            if d_cnt > 0 and y_cnt >= d_cnt * 2:
                spike.append(yi)

    def sort_key(i): return int(i.get("count", 0) or 0)
    high.sort(key=sort_key, reverse=True)
    new.sort(key=sort_key, reverse=True)
    spike.sort(key=sort_key, reverse=True)
    return {"high_priority": high, "new": new, "spike": spike}

def build_summary_metrics(yesterday: List[Dict[str, Any]], day_before: List[Dict[str, Any]]) -> Dict[str, Any]:
    events_y = sum(int(i.get("count", 0) or 0) for i in yesterday)
    events_d = sum(int(i.get("count", 0) or 0) for i in day_before)
    events_diff = events_y - events_d

    type_counts: Dict[str, int] = {}
    for i in yesterday:
        t = i.get("type", "unknown")
        type_counts[t] = type_counts.get(t, 0) + 1
    type_kinds = len(type_counts)

    affected_users = sum(int(i.get("userCount", 0) or 0) for i in yesterday)

    return {
        "event_count": events_y,
        "event_count_diff": events_diff,
        "issue_type_kinds": type_kinds,
        "affected_users": affected_users,
        "issue_type_counts": type_counts,  # ì›í•˜ë©´ í•˜ë‹¨ ìƒì„¸ìš©
    }

def diff_emoji(value: int) -> str:
    return "ğŸ“ˆ" if value > 0 else ("ğŸ“‰" if value < 0 else "â–")

# ==============================
# ë§í¬/í¬ë§·
# ==============================
def issue_permalink(issue: Dict[str, Any]) -> str:
    if issue.get("permalink"):
        return issue["permalink"]
    issue_id = issue.get("id")
    base = f"https://sentry.io/organizations/{SENTRY_ORG_SLUG}/issues/{issue_id}/"
    suffix = f"?project={SENTRY_PROJECT_ID}&environment={SENTRY_ENVIRONMENT}" if SENTRY_PROJECT_ID else ""
    return base + suffix

def format_issue_line(issue: Dict[str, Any], comment_map: Dict[str, Dict[str, Any]]) -> str:
    iid = issue.get("id")
    link = issue_permalink(issue)
    title = issue.get("title") or issue.get("shortId") or iid
    cnt = int(issue.get("count", 0) or 0)
    users = int(issue.get("userCount", 0) or 0)
    line = f"â€¢ <{link}|{title}> â€” {cnt} events, {users} users"
    cm = comment_map.get(iid)
    if cm:
        sev = (cm.get("severity") or "").upper()
        act = cm.get("action") or ""
        cmt = (cm.get("comment") or "").replace("**", "*")
        bits = []
        if sev: bits.append(f"*Severity:* {sev}")
        if act: bits.append(f"*Action:* {act}")
        if cmt: bits.append(f"*Note:* {cmt}")
        if bits:
            line += "\n  " + " | ".join(bits)
    return line

# ==============================
# AI ì½”ë©˜íŠ¸(ê²¬ê³ í™”)
# ==============================
def ai_comment_issues(categories: Dict[str, List[Dict[str, Any]]],
                      date_str: str,
                      max_items: int,
                      debug: bool = False) -> Dict[str, Dict[str, Any]]:
    if not client:
        return {}

    def brief(issue: Dict[str, Any]) -> Dict[str, Any]:
        return {
            "id": issue.get("id"),
            "shortId": issue.get("shortId"),
            "title": issue.get("title"),
            "level": issue.get("level"),
            "count": int(issue.get("count", 0) or 0),
            "userCount": int(issue.get("userCount", 0) or 0),
            "culprit": issue.get("culprit"),
            "isNew": issue.get("isNew", False),
            "type": issue.get("type"),
        }

    payload = {
        "date": date_str,
        "high_priority": [brief(i) for i in categories["high_priority"][:max_items]],
        "new": [brief(i) for i in categories["new"][:max_items]],
        "spike": [brief(i) for i in categories["spike"][:max_items]],
    }

    system = (
        "ë‹¹ì‹ ì€ ì‹œë‹ˆì–´ ëª¨ë°”ì¼ í¬ë˜ì‹œ/SRE ì—”ì§€ë‹ˆì–´ì…ë‹ˆë‹¤. "
        "ë°˜ë“œì‹œ JSON ê°ì²´ë§Œ ë°˜í™˜í•˜ì‹­ì‹œì˜¤(ê·¸ ì™¸ í…ìŠ¤íŠ¸ ê¸ˆì§€). "
        "í‚¤ëŠ” ë°˜ë“œì‹œ ê° ì´ìŠˆì˜ 'id' ì—¬ì•¼ í•©ë‹ˆë‹¤. "
        "í…ìŠ¤íŠ¸ì—ëŠ” Slack mrkdwnì„ ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë©° êµµê²Œ í‘œê¸°ëŠ” ë‹¨ì¼ ë³„í‘œ *í…ìŠ¤íŠ¸* ë§Œ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤."
    )
    user = (
        "ê° ì´ìŠˆì— ëŒ€í•´ í•œêµ­ì–´ë¡œ ê°„ë‹¨í•œ í‰ê°€ë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”. "
        "ë‹¤ìŒ í•„ë“œë¥¼ í¬í•¨í•˜ì—¬ JSON ê°ì²´(í‚¤=issue id)ë¡œë§Œ ë°˜í™˜í•˜ì„¸ìš”:\n"
        '- "severity": "high" | "medium" | "low"\n'
        '- "action": ì¦‰ì‹œ ì ìš© ê°€ëŠ¥í•œ í•œ ì¤„ í•´ê²°/ëŒ€ì‘ ë°©ì•ˆ(ì˜ˆ: ë„ ê°€ë“œ ì¶”ê°€, ë¡¤ë°±, ì¬ì‹œë„/ë°±ì˜¤í”„, SDK ë²„ì „ ê³ ì •/ë¡¤ë°±, ë¡œê·¸/ë¸Œë ˆë“œí¬ëŸ¼ ì¶”ê°€, í”Œë˜ê·¸ë¡œ ì„ì‹œ ì°¨ë‹¨ ë“±)\n'
        '- "comment": í•œ ì¤„ ì›ì¸ ì¶”ì •/íŠ¸ë¦¬ì•„ì§€ íŒíŠ¸\n\n'
        f"DATA:\n{json.dumps(payload, ensure_ascii=False)}"
    )

    raw = None
    try:
        # ì¼ë¶€ ëª¨ë¸ì—ì„œë§Œ ë™ì‘; ë¯¸ì§€ì›ì´ë©´ ë¬´ì‹œë¨
        resp = client.chat.completions.create(
            model=AI_MODEL,
            messages=[{"role":"system","content":system},{"role":"user","content":user}],
            temperature=0.2,
            response_format={"type":"json_object"}
        )
        raw = resp.choices[0].message.content.strip()
    except Exception as e:
        if debug: print(f"[ai_comment_issues] OpenAI í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return {}

    # ì½”ë“œíœìŠ¤ ì œê±°
    txt = raw
    if txt.startswith("```"):
        i = txt.find("{"); j = txt.rfind("}")
        if i != -1 and j != -1 and j > i:
            txt = txt[i:j+1]

    try:
        data = json.loads(txt)
    except Exception as e:
        if debug:
            print("[ai_comment_issues] JSON íŒŒì‹± ì‹¤íŒ¨. ì›ë¬¸:")
            print(raw)
            print("ì—ëŸ¬:", e)
        return {}

    # í‚¤ ê²€ì¦/ë³´ì •: ê¸°ëŒ€ id ì§‘í•©
    expected_ids = {i.get("id") for b in ("high_priority","new","spike") for i in categories[b][:max_items]}
    expected_ids = {x for x in expected_ids if x}

    if all(k in expected_ids for k in data.keys()):
        return data

    # í˜¹ì‹œ ì˜ëª»ëœ í‚¤(ì˜ˆ: shortId/title)ë¥¼ ì“´ ê²½ìš°, ê°’ ë‚´ë¶€ì˜ id ë˜ëŠ” ì—­ë§¤í•‘ìœ¼ë¡œ ë³´ì •
    fixed: Dict[str, Dict[str, Any]] = {}
    index_by = {}
    for b in ("high_priority","new","spike"):
        for iss in categories[b][:max_items]:
            if iss.get("shortId"):
                index_by[f"shortId::{iss['shortId']}"] = iss["id"]
            if iss.get("title"):
                index_by[f"title::{iss['title']}"] = iss["id"]

    for k, v in data.items():
        vid = v.get("id") if isinstance(v, dict) else None
        if vid in expected_ids:
            fixed[vid] = v; continue
        cand = index_by.get(f"shortId::{k}") or index_by.get(f"title::{k}")
        if cand:
            fixed[cand] = v; continue
        if k in expected_ids:
            fixed[k] = v

    if not fixed and debug:
        print("[ai_comment_issues] í‚¤ ë³´ì • ì‹¤íŒ¨. keys:", list(data.keys()))
        print("expected:", list(expected_ids))
    return fixed or {}

# ==============================
# Slack Blocks
# ==============================
def build_slack_payload(date_str: str,
                        metrics: Dict[str, Any],
                        crash_free: Dict[str, float],
                        categories: Dict[str, List[Dict[str, Any]]],
                        comment_map: Dict[str, Dict[str, Any]],
                        max_items: int,
                        expert_summary: Optional[str]) -> Dict[str, Any]:
    def section_for(label: str, key: str) -> Dict[str, Any]:
        issues = categories[key][:max_items]
        if not issues:
            text = f"*{label}*: ì—†ìŒ âœ…"
        else:
            lines = [format_issue_line(i, comment_map) for i in issues]
            text = f"*{label}*:\n" + "\n".join(lines)
        return {"type":"section","text":{"type":"mrkdwn","text":text}}

    blocks: List[Dict[str, Any]] = [
        {"type":"header","text":{"type":"plain_text","text":f"Android ì¼ê°„ ë¦¬í¬íŠ¸ Â· {date_str}"}},
        {
            "type":"section",
            "text":{"type":"mrkdwn","text":(
                "*ğŸ“Š ê¸°ë³¸ ì§€í‘œ*\n\n"
                f"- ì´ìŠˆ ë°œìƒ íšŸìˆ˜: {metrics['event_count']:,}ê±´ ({diff_emoji(metrics['event_count_diff'])} {metrics['event_count_diff']:+,}ê±´)\n"
                f"- í¬ë˜ì‹œ ì´ìŠˆ ì¢…ë¥˜: {metrics['issue_type_kinds']}ê°œ\n"
                f"- ì˜í–¥ë°›ì€ ì‚¬ìš©ì(ì–´ì œ): {metrics['affected_users']:,}ëª…\n"
                f"- Crash-Free Sessions(ì–´ì œ): {crash_free['crash_free_sessions_pct']}%\n"
                f"- Crash-Free Users(ì–´ì œ): {crash_free['crash_free_users_pct']}%\n"
            )}
        },
        {"type":"divider"},
        section_for("ğŸš¨ ìš°ì„ ìˆœìœ„ ë†’ì€ ì´ìŠˆ", "high_priority"),
        {"type":"divider"},
        section_for("ğŸ†• ì‹ ê·œ ì´ìŠˆ", "new"),
        {"type":"divider"},
        section_for("ğŸ“ˆ ê¸‰ì¦ ì´ìŠˆ", "spike"),
    ]

    if expert_summary:
        blocks.insert(2, {"type":"section","text":{"type":"mrkdwn","text":f"*ğŸ§  ì „ë¬¸ê°€ ì½”ë©˜íŠ¸*\n{expert_summary}"}})

    blocks.append({
        "type":"actions",
        "elements":[{
            "type":"button",
            "text":{"type":"plain_text","text":"Sentry ëŒ€ì‹œë³´ë“œ ì—´ê¸°"},
            "url": f"https://sentry.io/organizations/{SENTRY_ORG_SLUG}/projects/{SENTRY_PROJECT_SLUG}/?environment={SENTRY_ENVIRONMENT}"
        }]
    })
    return {"blocks": blocks}

# ==============================
# ì „ë¬¸ê°€ ìš”ì•½(í•œêµ­ì–´)
# ==============================
def ai_overall_summary(date_str: str,
                       metrics: Dict[str, Any],
                       crash_free: Dict[str, float],
                       categories: Dict[str, List[Dict[str, Any]]]) -> Optional[str]:
    if not client:
        return None
    summary_data = {
        "date": date_str,
        "event_count": metrics["event_count"],
        "event_count_diff": metrics["event_count_diff"],
        "issue_type_kinds": metrics["issue_type_kinds"],
        "affected_users": metrics["affected_users"],
        "crash_free_sessions_pct": crash_free["crash_free_sessions_pct"],
        "crash_free_users_pct": crash_free["crash_free_users_pct"],
        "top_high_priority_titles": [ (i.get("title") or i.get("shortId") or i.get("id")) for i in categories["high_priority"][:3] ],
        "top_spike_titles": [ (i.get("title") or i.get("shortId") or i.get("id")) for i in categories["spike"][:3] ],
        "counts": {
            "high_priority": len(categories["high_priority"]),
            "new": len(categories["new"]),
            "spike": len(categories["spike"]),
        }
    }
    system = (
        "ë‹¹ì‹ ì€ ì‹œë‹ˆì–´ ëª¨ë°”ì¼ í¬ë˜ì‹œ/SRE ì—”ì§€ë‹ˆì–´ì…ë‹ˆë‹¤. "
        "Slack mrkdwn í˜•ì‹ìœ¼ë¡œ ê°„ê²°í•˜ê³  ì‹¤í–‰ ì¤‘ì‹¬ì˜ ìš”ì•½ì„ ì‘ì„±í•˜ì„¸ìš”. "
        "ë‹¨ì¼ ë³„í‘œ *í…ìŠ¤íŠ¸* ë¡œë§Œ êµµê²Œ í‘œì‹œí•˜ì„¸ìš”. "
        "ìˆ˜ì¹˜ë¥¼ ë‹¨ìˆœ ë‚˜ì—´í•˜ì§€ ë§ê³ , ì˜ë¯¸/ì›ì¸ ì¶”ì •/ìš°ì„ ìˆœìœ„/ì¦‰ì‹œ ëŒ€ì‘ ë°©ì•ˆì„ ì œì‹œí•˜ì„¸ìš”. "
        "ë¶ˆë¦¿ 4~6ê°œë¡œ ì œí•œí•˜ì„¸ìš”."
    )
    user = (
        "ë‹¤ìŒ JSONì„ ë¶„ì„í•´ ì¢…í•© ì½”ë©˜íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.\n"
        "- ê°€ì¥ ì˜í–¥ë ¥ì´ í° ë¬¸ì œ(Top high/spike)ì— ì§‘ì¤‘\n"
        "- íŒ€ì´ ì˜¤ëŠ˜ ë°”ë¡œ í•  ìˆ˜ ìˆëŠ” ì•¡ì…˜ ì œì•ˆ\n\n"
        f"DATA:\n{json.dumps(summary_data, ensure_ascii=False)}"
    )
    try:
        resp = client.chat.completions.create(
            model=AI_MODEL,
            messages=[{"role":"system","content":system},{"role":"user","content":user}],
            temperature=0.2,
        )
        text = resp.choices[0].message.content.strip()
        return text.replace("**", "*")
    except Exception:
        return None

# ==============================
# Slack ì „ì†¡
# ==============================
def send_to_slack(blocks_payload: Dict[str, Any], fallback_text: str) -> None:
    if TEST_MODE:
        print("[TEST_MODE=true] Slack ì „ì†¡ ìƒëµ. (í”„ë¦¬ë·°)")
        print(json.dumps(blocks_payload, ensure_ascii=False, indent=2))
        return
    if not SLACK_WEBHOOK_URL:
        print("[WARN] SLACK_WEBHOOK_URL ë¯¸ì„¤ì •. ì „ì†¡ ë¶ˆê°€. í”„ë¦¬ë·° ì¶œë ¥.")
        print(json.dumps(blocks_payload, ensure_ascii=False, indent=2))
        return
    payload = {"text": fallback_text, **blocks_payload}
    resp = requests.post(
        SLACK_WEBHOOK_URL,
        data=json.dumps(payload),
        headers={"Content-Type": "application/json"},
        timeout=15
    )
    resp.raise_for_status()
    print("[INFO] Slack ì „ì†¡ ì„±ê³µ")

# ==============================
# ë©”ì¸
# ==============================
def main():
    parser = argparse.ArgumentParser(description="Actionable Sentry Daily Report â†’ Slack")
    parser.add_argument("--date", help="ê¸°ì¤€ì¼(YYYY-MM-DD, KST). ë¯¸ì§€ì • ì‹œ ì–´ì œ.")
    parser.add_argument("--no-ai", action="store_true", help="AI ì½”ë©˜íŠ¸ ë¹„í™œì„±í™”")
    parser.add_argument("--max", type=int, default=DEFAULT_MAX_ITEMS, help="ì¹´í…Œê³ ë¦¬ë³„ í‘œì‹œ ìµœëŒ€ ì´ìŠˆ ìˆ˜")
    args = parser.parse_args()

    # í•„ìˆ˜ env í™•ì¸
    for k, v in {
        "SENTRY_AUTH_TOKEN": SENTRY_AUTH_TOKEN,
        "SENTRY_ORG_SLUG": SENTRY_ORG_SLUG,
        "SENTRY_PROJECT_SLUG": SENTRY_PROJECT_SLUG,
        "SENTRY_PROJECT_ID": SENTRY_PROJECT_ID,
    }.items():
        if not v:
            raise SystemExit(f"[ERROR] Missing env: {k}")

    max_items = args.max
    y_kst, dby_kst = y_and_dby(args.date)

    # ì´ìŠˆ ìˆ˜ì§‘(ì „ëŸ‰)
    y_issues = fetch_issues_all(y_kst, y_kst)
    d_issues = fetch_issues_all(dby_kst, dby_kst)

    # ë¶„ë¥˜/ìš”ì•½
    categories = classify_issues(y_issues, d_issues)
    metrics = build_summary_metrics(y_issues, d_issues)
    crash_free = fetch_crash_free_rates_kst(y_kst)

    # AI ì½”ë©˜íŠ¸/ìš”ì•½
    comment_map: Dict[str, Dict[str, Any]] = {}
    expert_summary: Optional[str] = None
    if (not args.no_ai) and client:
        comment_map = ai_comment_issues(categories, y_kst, max_items, debug=False)
        expert_summary = ai_overall_summary(y_kst, metrics, crash_free, categories)

    # Slack Blocks
    blocks = build_slack_payload(
        date_str=y_kst,
        metrics=metrics,
        crash_free=crash_free,
        categories=categories,
        comment_map=comment_map,
        max_items=max_items,
        expert_summary=expert_summary
    )

    fallback = (
        f"Android ì¼ê°„ ë¦¬í¬íŠ¸ {y_kst} â€” Events {metrics['event_count']:,} "
        f"({metrics['event_count_diff']:+,}), Crash-Free S {crash_free['crash_free_sessions_pct']}% "
        f"U {crash_free['crash_free_users_pct']}%"
    )
    send_to_slack(blocks, fallback)

if __name__ == "__main__":
    main()